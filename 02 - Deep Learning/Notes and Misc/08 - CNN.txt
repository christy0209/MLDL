A Convolutional Neural Network (ConvNet/CNN) is a Deep Learning algorithm which can take in an input image, 
assign importance (learnable weights and biases) to various aspects/objects in the image and be able to differentiate one from the other. 
The pre-processing required in a ConvNet is much lower as compared to other classification algorithms. 
While in primitive methods filters are hand-engineered, with enough training, 
ConvNets have the ability to learn these filters/characteristics.

Why ConvNets over Feed-Forward Neural Nets?

An image is nothing but a matrix of pixel values, right? 
So why not just flatten the image (e.g. 3x3 image matrix into a 9x1 vector) and feed it to a Multi-Level Perceptron for classification purposes? 

A ConvNet is able to successfully capture the Spatial and Temporal dependencies in an image through the application of relevant filters. 
The architecture performs a better fitting to the image dataset due to the reduction in the number of parameters involved and reusability 
of weights. In other words, the network can be trained to understand the sophistication of the image better.

The role of the ConvNet is to reduce the images into a form which is easier to process, 
without losing features which are critical for getting a good prediction

